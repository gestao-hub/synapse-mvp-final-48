import { useEffect, useRef, useState } from 'react'

interface AudioDetectorState {
  isActive: boolean
  level: number
}

export function useSimpleAudioDetector(
  mediaStream: MediaStream | null,
  audioElement: HTMLAudioElement | null
): AudioDetectorState {
  const [isActive, setIsActive] = useState(false)
  const [level, setLevel] = useState(0)
  
  const audioContextRef = useRef<AudioContext | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const animationFrameRef = useRef<number | null>(null)

  useEffect(() => {
    let cleanup: (() => void) | null = null

  const setupAudioAnalysis = async () => {
    try {
      console.log('üîß Configurando an√°lise de √°udio:', {
        hasMediaStream: !!mediaStream,
        hasAudioElement: !!audioElement,
        audioElementSrc: audioElement?.src,
        audioElementSrcObject: !!audioElement?.srcObject
      })

      // Priorizar mediaStream (microfone) sobre audioElement
      if (mediaStream) {
        console.log('‚úÖ Configurando an√°lise de MICROFONE')
        const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
        const analyser = audioContext.createAnalyser()
        const source = audioContext.createMediaStreamSource(mediaStream)
        
        analyser.fftSize = 512
        analyser.smoothingTimeConstant = 0.8
        source.connect(analyser)
        
        audioContextRef.current = audioContext
        analyserRef.current = analyser
        
        console.log('‚úì An√°lise de microfone configurada SUCESSO')
        
        cleanup = () => {
          console.log('üßπ Limpando contexto de microfone')
          if (audioContext.state !== 'closed') {
            audioContext.close()
          }
        }
      } else if (audioElement) {
        console.log('‚úÖ Tentando configurar an√°lise de AUDIO ELEMENTO')
        
        // Fun√ß√£o para configurar √°udio quando estiver pronto
        const setupAudioElement = () => {
          console.log('üîÑ Verificando se audioElement est√° pronto para an√°lise:', {
            readyState: audioElement.readyState,
            currentTime: audioElement.currentTime,
            duration: audioElement.duration,
            paused: audioElement.paused,
            ended: audioElement.ended,
            src: audioElement.src,
            srcObject: !!audioElement.srcObject
          })
          
          const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
          const analyser = audioContext.createAnalyser()
          
          try {
            const source = audioContext.createMediaElementSource(audioElement)
            analyser.fftSize = 512
            analyser.smoothingTimeConstant = 0.8
            source.connect(analyser)
            source.connect(audioContext.destination) // Para manter o playback
            
            audioContextRef.current = audioContext
            analyserRef.current = analyser
            
            console.log('‚úì An√°lise de √°udio remoto configurada SUCESSO')
            
            cleanup = () => {
              console.log('üßπ Limpando contexto de √°udio remoto')
              if (audioContext.state !== 'closed') {
                audioContext.close()
              }
            }
            
            return true
          } catch (error) {
            console.warn('‚ùå N√£o foi poss√≠vel conectar ao audioElement:', error.message)
            audioContext.close()
            return false
          }
        }
        
        // Tentar configurar imediatamente
        if (setupAudioElement()) {
          console.log('‚úÖ AudioElement configurado imediatamente')
        } else {
          console.log('‚è≥ AudioElement n√£o est√° pronto, aguardando eventos...')
          
          // Aguardar eventos do audioElement
          const onLoadedData = () => {
            console.log('üì° AudioElement loadeddata event')
            if (setupAudioElement()) {
              audioElement.removeEventListener('loadeddata', onLoadedData)
              audioElement.removeEventListener('canplay', onCanPlay)
              audioElement.removeEventListener('playing', onPlaying)
            }
          }
          
          const onCanPlay = () => {
            console.log('üì° AudioElement canplay event')
            if (setupAudioElement()) {
              audioElement.removeEventListener('loadeddata', onLoadedData)
              audioElement.removeEventListener('canplay', onCanPlay)
              audioElement.removeEventListener('playing', onPlaying)
            }
          }
          
          const onPlaying = () => {
            console.log('üì° AudioElement playing event')
            if (setupAudioElement()) {
              audioElement.removeEventListener('loadeddata', onLoadedData)
              audioElement.removeEventListener('canplay', onCanPlay)
              audioElement.removeEventListener('playing', onPlaying)
            }
          }
          
          audioElement.addEventListener('loadeddata', onLoadedData)
          audioElement.addEventListener('canplay', onCanPlay)
          audioElement.addEventListener('playing', onPlaying)
          
          // Cleanup adicional para eventos
          const originalCleanup = cleanup
          cleanup = () => {
            audioElement.removeEventListener('loadeddata', onLoadedData)
            audioElement.removeEventListener('canplay', onCanPlay)
            audioElement.removeEventListener('playing', onPlaying)
            if (originalCleanup) originalCleanup()
          }
        }
      } else {
        console.warn('‚ùå Nenhuma fonte de √°udio v√°lida dispon√≠vel')
        return
      }

      // Iniciar loop de an√°lise
      if (analyserRef.current) {
        console.log('üîÑ Iniciando loop de an√°lise de √°udio')
        let frameCount = 0
        
        const analyzeAudio = () => {
          if (!analyserRef.current) return

          const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
          analyserRef.current.getByteFrequencyData(dataArray)

          // Calcular n√≠vel m√©dio
          let sum = 0
          for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i]
          }
          const avgLevel = sum / dataArray.length / 255

          // Aplicar threshold mais sens√≠vel
          const threshold = 0.03 // Ainda mais sens√≠vel
          const currentlyActive = avgLevel > threshold

          setLevel(avgLevel)
          setIsActive(currentlyActive)

          // Log peri√≥dico para debug
          frameCount++
          if (frameCount % 60 === 0) { // Log a cada 60 frames (~1 segundo)
            console.log(`üìä Frame ${frameCount}: avgLevel=${Math.round(avgLevel * 100)}%, active=${currentlyActive}`)
          }

          if (currentlyActive) {
            console.log(`üé§ √ÅUDIO DETECTADO: ${Math.round(avgLevel * 100)}% (threshold: ${Math.round(threshold * 100)}%)`)
          }

          animationFrameRef.current = requestAnimationFrame(analyzeAudio)
        }

        analyzeAudio()
      } else {
        console.error('‚ùå analyserRef.current is null - n√£o foi poss√≠vel iniciar an√°lise')
      }
      } catch (error) {
        console.error('Erro ao configurar an√°lise de √°udio:', error)
        setIsActive(false)
        setLevel(0)
      }
    }

    setupAudioAnalysis()

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
      }
      if (cleanup) {
        cleanup()
      }
      setIsActive(false)
      setLevel(0)
    }
  }, [mediaStream, audioElement])

  return { isActive, level }
}